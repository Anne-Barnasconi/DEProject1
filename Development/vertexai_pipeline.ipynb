{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball win percentage prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --user --no-cache-dir --upgrade \"kfp>2\" \"google-cloud-pipeline-components>2\" \\\n",
    "                                        google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Google Cloud project that this pipeline runs in.\n",
    "PROJECT_ID = \"your project id\"\n",
    "# The region that this pipeline runs in\n",
    "REGION = \"us-central1\"\n",
    "# Specify a Cloud Storage URI that your pipelines service account can access. The artifacts of your pipeline runs are stored within the pipeline root.\n",
    "PIPELINE_ROOT = \"gs://your temp bucket\"\n",
    "\n",
    "\n",
    "# The model_repo is specified in the pipeline definition\n",
    "# Threshold values are specified in the pipelien definition\n",
    "# Data url is specified in the pipeline definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import typing\n",
    "from typing import Dict\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "import google.cloud.aiplatform as aip\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline components\n",
    "Components include:\n",
    "* Load data\n",
    "* Train model\n",
    "* Evaluate model\n",
    "* Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League</th>\n",
       "      <th>On_base_percentage</th>\n",
       "      <th>Slugging_percentage</th>\n",
       "      <th>Batting_average</th>\n",
       "      <th>Opponent_on_base_percentage</th>\n",
       "      <th>Opponent_slugging_percentage</th>\n",
       "      <th>Win_percentage</th>\n",
       "      <th>decade60s</th>\n",
       "      <th>decade70s</th>\n",
       "      <th>decade80s</th>\n",
       "      <th>decade90s</th>\n",
       "      <th>decade2000s</th>\n",
       "      <th>decade2010s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.465839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     League  On_base_percentage  Slugging_percentage  Batting_average  \\\n",
       "0         1               0.328                0.418            0.259   \n",
       "1         1               0.320                0.389            0.247   \n",
       "2         0               0.311                0.417            0.247   \n",
       "3         0               0.315                0.415            0.260   \n",
       "4         1               0.302                0.378            0.240   \n",
       "..      ...                 ...                  ...              ...   \n",
       "415       1               0.356                0.434            0.271   \n",
       "416       1               0.338                0.426            0.262   \n",
       "417       0               0.343                0.411            0.274   \n",
       "418       0               0.361                0.479            0.293   \n",
       "419       0               0.352                0.457            0.280   \n",
       "\n",
       "     Opponent_on_base_percentage  Opponent_slugging_percentage  \\\n",
       "0                          0.317                         0.415   \n",
       "1                          0.306                         0.378   \n",
       "2                          0.315                         0.403   \n",
       "3                          0.331                         0.428   \n",
       "4                          0.335                         0.424   \n",
       "..                           ...                           ...   \n",
       "415                        0.345                         0.423   \n",
       "416                        0.355                         0.427   \n",
       "417                        0.371                         0.448   \n",
       "418                        0.346                         0.459   \n",
       "419                        0.353                         0.456   \n",
       "\n",
       "     Win_percentage  decade60s  decade70s  decade80s  decade90s  decade2000s  \\\n",
       "0          0.500000          0          0          0          0            0   \n",
       "1          0.580247          0          0          0          0            0   \n",
       "2          0.574074          0          0          0          0            0   \n",
       "3          0.425926          0          0          0          0            0   \n",
       "4          0.376543          0          0          0          0            0   \n",
       "..              ...        ...        ...        ...        ...          ...   \n",
       "415        0.530864          0          0          0          1            0   \n",
       "416        0.465839          0          0          0          1            0   \n",
       "417        0.425926          0          0          0          1            0   \n",
       "418        0.586420          0          0          0          1            0   \n",
       "419        0.518519          0          0          0          1            0   \n",
       "\n",
       "     decade2010s  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "415            0  \n",
       "416            0  \n",
       "417            0  \n",
       "418            0  \n",
       "419            0  \n",
       "\n",
       "[420 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List columns\n",
    "import pandas as pd\n",
    "df_baseball = pd.read_csv(\"https://raw.githubusercontent.com/Anne-Barnasconi/DEProject1/refs/heads/main/Data/baseball_clean.csv?token=GHSAT0AAAAAACXJCXZT2EROZL6L2AA24QW2ZYOK5EQ\", delimiter=\",\")\n",
    "df_baseball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\",\"google-cloud-storage\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def download_data(project_id: str, bucket: str, file_name: str, dataset: Output[Dataset]):\n",
    "    '''download data'''\n",
    "    from google.cloud import storage\n",
    "    import pandas as pd\n",
    "    import logging \n",
    "    import sys\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    # Downloaing the file from a google bucket \n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.bucket(bucket)\n",
    "    blob = bucket.blob(file_name)\n",
    "    blob.download_to_filename(dataset.path + \".csv\")\n",
    "    logging.info('Downloaded Data!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn==1.3.2\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def train_test_split_scale(dataset: Input[Dataset], X_train: Output[Dataset], X_test: Output[Dataset], y_train: Output[Dataset], y_test: Output[Dataset]):\n",
    "    '''train_test_split and feature scaling'''\n",
    "    import pandas as pd\n",
    "    import logging \n",
    "    import sys\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO) \n",
    "    \n",
    "    # load all data, create prediction (y) and feature sets (X)\n",
    "    alldata = pd.read_csv(dataset.path, index_col=None)\n",
    "    X = alldata.drop(labels=['Win_percentage'],axis=1)\n",
    "    y = alldata['Win_percentage']\n",
    "    \n",
    "    # Split test and train data\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, random_state=0)\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train,columns=X.columns)\n",
    "    X_test = pd.DataFrame(X_test,columns=X.columns)\n",
    "    \n",
    "    # Put data in csv files\n",
    "    X_train.to_csv(X_train.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
    "    X_test.to_csv(X_test.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
    "    y_train.to_csv(y_train.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
    "    y_test.to_csv(y_test.path + \".csv\" , index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the KNN Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=['pandas', 'scikit-learn==1.3.2'],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def train_model(X_train: Input[Dataset], y_train: Input[Dataset], out_model: Output[Model]):\n",
    "    '''train a KNN regressor with default parameters (k = 4)'''\n",
    "    import pandas as pd\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import json\n",
    "    import logging \n",
    "    import sys\n",
    "    import os\n",
    "    import pickle\n",
    "       \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    # Load the train set\n",
    "    X_train = pd.read_csv(X_train.path+\".csv\")\n",
    "    y_train = pd.read_csv(y_train.path+\".csv\")\n",
    "    \n",
    "    # Log the train information\n",
    "    logging.info(X_train.columns)\n",
    "    logging.info(X_train.columns)        \n",
    "  \n",
    "    # Train the model\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=4)\n",
    "    model_knn.fit(X_train,y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    out_model.metadata[\"framework\"] = \"KNN\"\n",
    "    file_name = out_model.path + \".pkl\"\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(model_knn, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=['pandas', 'scikit-learn==1.3.2'],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def evaluate_model(model_knn: Input[Model], X_test: Input[Dataset], y_test: Input[Dataset], thresholds_dict_str: str, metrics_dict: Output[Metrics]) -> NamedTuple('outputs', deploy=bool):\n",
    "    '''evaluate the KNN regressor'''\n",
    "    import pandas as pd\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.metrics import root_mean_squared_error\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import json\n",
    "    import logging \n",
    "    import sys\n",
    "    import os\n",
    "    import pickle\n",
    "       \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    # Create threshold_check function\n",
    "    def threshold_check(val1, val2):\n",
    "        cond = False\n",
    "        if val1 >= val2 :\n",
    "            cond = True\n",
    "        return cond\n",
    "    \n",
    "    # Load data and model\n",
    "    X_test = pd.read_csv(X_test.path+\".csv\")\n",
    "    y_test = pd.read_csv(y_test.path+\".csv\")\n",
    "    model = KNeighborsRegressor()\n",
    "    file_name = model_knn.path + \".pkl\"\n",
    "    with open(file_name, 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Prepare the data for evaluation\n",
    "    y_pred = model.predict(y_test)\n",
    "    \n",
    "    \n",
    "\n",
    "    logging.info(metrics_dict)\n",
    "\n",
    "    # Compute R^2\n",
    "    r_squared = model_knn.score(X_test, y_test)\n",
    "    \n",
    "    # Load threshold from JSON file\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    model_knn.metadata[\"R-squared\"] = float(r_squared)\n",
    "    outputs = NamedTuple('outputs', deploy=bool)\n",
    "    approval_value = threshold_check(float(r_squared), int(thresholds_dict['R-squared']))\n",
    "    \n",
    "    # Log R^2 for the training set - Note: In the original testing, we also used MSE but I've left it out here\n",
    "    metrics_dict = {\n",
    "        \"R-squared\": r_squared,\n",
    "        \"RMSE\": root_mean_squared_error(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return outputs(approval_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def upload_model_to_gcs(project_id: str, model_repo: str, model_name:str, model: Input[Model]):\n",
    "    '''upload model to gsc'''\n",
    "    from google.cloud import storage   \n",
    "    import logging \n",
    "    import sys\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)    \n",
    "  \n",
    "    # upload the model to GCS\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.bucket(model_repo)\n",
    "    dest_file_name= model_name + '.pkl'\n",
    "    blob = bucket.blob(dest_file_name)\n",
    "    source_file_name= model.path + '.pkl'\n",
    "   \n",
    "    blob.upload_from_filename(source_file_name)    \n",
    "    \n",
    "    print(f\"File {source_file_name} uploaded to {model_repo}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"pipeline-moneyball\",\n",
    "    \n",
    ")\n",
    "def pipeline(\n",
    "    url: str = \"https://raw.githubusercontent.com/Anne-Barnasconi/DEProject1/refs/heads/main/Data/baseball_clean.csv?token=GHSAT0AAAAAACXJCXZTA4LFIREMA4456RYKZYOQDFQ\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION, \n",
    "    thresholds_dict_str: str = '{\"R-squared\":0.7}',  # Threshold set to 0.7\n",
    "    model_repo: str = \"models_de2024_trs\"\n",
    "    ):\n",
    "    \n",
    "    # Loading the data\n",
    "    data_op = download_data(url=url)\n",
    "    \n",
    "    # Splitting and scaling the model\n",
    "    split_scale_model_op = train_test_split_scale(\n",
    "        dataset = data_op.outputs[\"dataset_train\"])\n",
    "    \n",
    "    # Training the model\n",
    "    model_train_op = train_model(\n",
    "        X_train = split_scale_model_op.outputs[\"X_train\"], \n",
    "        y_train = split_scale_model_op.outputs[\"y_train\"])\n",
    "    \n",
    "    # Evaluating the model\n",
    "    model_evaluation_op = evaluate_model(\n",
    "        model_knn = model_train_op.outputs[\"out_model\"],\n",
    "        X_test = split_scale_model_op.outputs[\"X_test\"],\n",
    "        y_test = split_scale_model_op.outputs[\"test\"],\n",
    "        thresholds_dict_str = thresholds_dict_str\n",
    "    )\n",
    "\n",
    "    \n",
    "    with dsl.If(\n",
    "        model_evaluation_op.outputs[\"deploy\"]==True,\n",
    "        name=\"deploy-model\",\n",
    "    ):\n",
    "           \n",
    "        upload_model_to_gc_op = upload_model_to_gcs(\n",
    "            project_id=project,\n",
    "            model_repo=model_repo,\n",
    "            model_name=\"moneyball\",\n",
    "            model = model_train_op.outputs['out_model']\n",
    "        )    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path = 'ml_moneyball.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    ")\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=\"moneyball-pipeline\",\n",
    "    template_path=\"ml_moneyball.yaml\",\n",
    "    enable_caching=False,\n",
    "    location=REGION,\n",
    ")\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
